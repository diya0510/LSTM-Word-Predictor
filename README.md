# ğŸ§  LSTM Next-Word Predictor

A simple LSTM-based next-word prediction model trained on AI-related text to demonstrate language modeling and text generation using TensorFlow and Keras.

---

## ğŸ“Œ Features

- Preprocessing: tokenization, sequence generation, and padding
- LSTM model architecture for sequence prediction
- One-hot encoding of output for multi-class classification
- Predictive loop for generating text word-by-word
- Small custom dataset focused on Artificial Intelligence topics

---

## ğŸ§ª How to Use

1. Open the notebook in [Google Colab](https://colab.research.google.com/).
2. Run all cells to train the model and see predictions.
3. Modify the `text` variable or replace it with your own corpus to try different results.

---

## ğŸ“ Dataset

This project uses a short paragraph about **Artificial Intelligence** and its subfields like Machine Learning, NLP, Computer Vision, etc., for training purposes.

---

## ğŸš€ Future Ideas

- Replace dataset with larger corpora like Wikipedia dumps or books
- Add temperature sampling for varied predictions
- Use pretrained embeddings like GloVe
- Wrap into a simple Streamlit web app

---

